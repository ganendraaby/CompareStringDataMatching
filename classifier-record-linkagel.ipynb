{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df1325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (97, 30)\n",
      "Sample data:\n",
      "                                      Authors  \\\n",
      "0                I Lewaa, MS Hafez, MA Ismail   \n",
      "1  M El Abassi, M Amnai, A Choukri, Y Fakhri…   \n",
      "2             J Yang, K Xian, P Wang, Y Zhang   \n",
      "3                     J Yang, S Quan, P Wang…   \n",
      "4                               Y Zhu, J Yang   \n",
      "\n",
      "                                               Title  \\\n",
      "0  Data integration using statistical matching te...   \n",
      "1  Matching data detection for the integration sy...   \n",
      "2  A performance evaluation of correspondence gro...   \n",
      "3  Evaluating local geometric feature representat...   \n",
      "4  Automatic data matching for geospatial models:...   \n",
      "\n",
      "                            Source  \n",
      "0  Statistical Journal of the IAOS  \n",
      "1       International Journal of …  \n",
      "2   IEEE transactions on pattern …  \n",
      "3           IEEE Transactions on …  \n",
      "4                    Annals of GIS  \n",
      "\n",
      "Cleaning data...\n",
      "Data cleaning completed.\n",
      "clean dataframe saved to clean_popcite.csv!\n",
      "\n",
      "Generating all possible pairs...\n",
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 9409 candidate pairs (all possible combinations)\n",
      "\n",
      "Comparison step...\n",
      "Computing comparisons... This may take a while for large datasets.\n",
      "Comparisons after removing self-matches: 9312\n",
      "All pairwise comparison results saved to 'all_pairwise_comparisons.csv'\n",
      "\n",
      "Comparison completed!\n",
      "Total records: 97\n",
      "Total pairwise comparisons: 9312\n",
      "Total pairwise matches (rows in features): 9312\n",
      "2\n",
      "       authors  title  source_exact\n",
      "48 83      1.0    1.0             1\n",
      "83 48      1.0    1.0             1\n",
      "All matched pairs saved to 'all_matched_pairs.csv'\n",
      "Potential matches saved to 'matches.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.preprocessing import clean\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Read your CSV file\n",
    "df = pd.read_csv('clean_popcite.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Sample data:\")\n",
    "print(df[['Authors', 'Title', 'Source']].head())\n",
    "\n",
    "# Data preprocessing - clean the fields\n",
    "print(\"\\nCleaning data...\")\n",
    "\n",
    "# First remove rows with NaN values in critical columns\n",
    "df = df.dropna(subset=['Authors', 'Title', 'Source'])\n",
    "\n",
    "# Then clean the remaining data\n",
    "df['Authors_clean'] = clean(df['Authors'], \n",
    "                           lowercase=True, \n",
    "                           remove_brackets=True, \n",
    "                           strip_accents='unicode')\n",
    "\n",
    "df['Title_clean'] = clean(df['Title'], \n",
    "                         lowercase=True, \n",
    "                         remove_brackets=True, \n",
    "                         strip_accents='unicode')\n",
    "\n",
    "df['Source_clean'] = clean(df['Source'], \n",
    "                          lowercase=True, \n",
    "                          remove_brackets=True, \n",
    "                          strip_accents='unicode')\n",
    "\n",
    "print(\"Data cleaning completed.\")\n",
    "\n",
    "clean_csv = df.to_csv(\"clean_popcite.csv\")\n",
    "\n",
    "print(f\"clean dataframe saved to clean_popcite.csv!\")\n",
    "\n",
    "# INDEXATION STEP - Generate ALL possible pairs\n",
    "print(\"\\nGenerating all possible pairs...\")\n",
    "indexer = rl.Index()\n",
    "\n",
    "# Use full indexing instead of blocking to get ALL pairs\n",
    "indexer.full()\n",
    "\n",
    "# Generate ALL candidate pairs for deduplication\n",
    "candidate_links = indexer.index(df, df)\n",
    "\n",
    "print(f\"Generated {len(candidate_links)} candidate pairs (all possible combinations)\")\n",
    "\n",
    "# COMPARISON STEP\n",
    "print(\"\\nComparison step...\")\n",
    "compare_cl = rl.Compare()\n",
    "\n",
    "# Add comparison methods for each field\n",
    "compare_cl.string('Authors_clean', 'Authors_clean', \n",
    "                  method='cosine', threshold=0.5, label='authors')\n",
    "\n",
    "compare_cl.string('Title_clean', 'Title_clean', \n",
    "                  method='cosine', threshold=0.5, label='title')\n",
    "\n",
    "compare_cl.exact('Source_clean', 'Source_clean', label='source_exact')\n",
    "\n",
    "\n",
    "# Optional: Add year comparison if needed\n",
    "# if 'Year' in df.columns:\n",
    "#     compare_cl.exact('Year', 'Year', label='year')\n",
    "\n",
    "# Compute comparison features for all candidate pairs\n",
    "print(\"Computing comparisons... This may take a while for large datasets.\")\n",
    "features = compare_cl.compute(candidate_links, df, df)\n",
    "features = features[features.index.get_level_values(0) != features.index.get_level_values(1)]\n",
    "print(f\"Comparisons after removing self-matches: {len(features)}\")\n",
    "\n",
    "# Save all comparison results to CSV\n",
    "features.reset_index().to_csv('all_pairwise_comparisons.csv', index=False)\n",
    "print(f\"All pairwise comparison results saved to 'all_pairwise_comparisons.csv'\")\n",
    "\n",
    "print(f\"\\nComparison completed!\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Total pairwise comparisons: {len(features)}\")\n",
    "print(f\"Total pairwise matches (rows in features): {features.shape[0]}\")\n",
    "matches = features[features.sum(axis=1) > 2]\n",
    "print(len(matches))\n",
    "print(matches.head())\n",
    "# Collect all matched pairs into a single DataFrame and save as one CSV\n",
    "matched_pairs = []\n",
    "for idx, row in matches.iterrows():\n",
    "    idx1, idx2 = row.name  # MultiIndex: (index1, index2)\n",
    "    matched_pairs.append({\n",
    "        'Record1_Index': idx1,\n",
    "        'Record2_Index': idx2,\n",
    "        'Record1_Authors': df.loc[idx1, 'Authors'],\n",
    "        'Record1_Title': df.loc[idx1, 'Title'],\n",
    "        'Record1_Source': df.loc[idx1, 'Source'],\n",
    "        'Record2_Authors': df.loc[idx2, 'Authors'],\n",
    "        'Record2_Title': df.loc[idx2, 'Title'],\n",
    "        'Record2_Source': df.loc[idx2, 'Source']\n",
    "    })\n",
    "matched_pairs_df = pd.DataFrame(matched_pairs)\n",
    "matched_pairs_df.to_csv('all_matched_pairs.csv', index=False)\n",
    "print(f\"All matched pairs saved to 'all_matched_pairs.csv'\")\n",
    "\n",
    "matches.reset_index().to_csv('matches.csv', index=False)\n",
    "print(f\"Potential matches saved to 'matches.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6b2faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STARTING ECM CLASSIFICATION\n",
      "==================================================\n",
      "\n",
      "Preparing feature matrix for ECM...\n",
      "Feature matrix shape: (9312, 3)\n",
      "Feature columns: ['authors', 'title', 'source_exact']\n",
      "Sample of feature matrix:\n",
      "     authors  title  source_exact\n",
      "0 1        0      1             0\n",
      "  2        0      1             0\n",
      "  3        0      1             0\n",
      "  4        0      1             0\n",
      "  5        0      1             0\n",
      "\n",
      "Initializing ECM Classifier...\n",
      "Training ECM model... This may take some time.\n",
      "\n",
      "ECM Training completed!\n",
      "\n",
      "----------------------------------------\n",
      "LEARNED ECM PARAMETERS\n",
      "----------------------------------------\n",
      "Prior probability P(Match): 0.0268\n",
      "m probabilities P(x_i=1|Match): {'authors': {np.int64(0): np.float64(0.43046841777582595), np.int64(1): np.float64(0.5695315822241744)}, 'title': {np.int64(0): np.float64(0.10476017857410284), np.int64(1): np.float64(0.8952398214258974)}, 'source_exact': {np.int64(0): np.float64(0.9808389900721138), np.int64(1): np.float64(0.019161009927886597)}}\n",
      "u probabilities P(x_i=1|Non-Match): {'authors': {np.int64(0): np.float64(0.97747957114325), np.int64(1): np.float64(0.022520428856748653)}, 'title': {np.int64(0): np.float64(0.25708243445103784), np.int64(1): np.float64(0.7429175655489617)}, 'source_exact': {np.int64(0): np.float64(0.9954511017375988), np.int64(1): np.float64(0.004548898262401295)}}\n",
      "Feature weights: {'authors': {np.int64(0): np.float64(0.4403861016474795), np.int64(1): np.float64(25.289553136262946)}, 'title': {np.int64(0): np.float64(0.40749644680237673), np.int64(1): np.float64(1.2050325136199744)}, 'source_exact': {np.int64(0): np.float64(0.9853211155826952), np.int64(1): np.float64(4.21223092331192)}}\n",
      "\n",
      "----------------------------------------\n",
      "MAKING PREDICTIONS\n",
      "----------------------------------------\n",
      "Predicting matches...\n",
      "ECM predicted 4 matches out of 9312 candidate pairs\n",
      "Computing match probabilities...\n",
      "\n",
      "Creating detailed results...\n",
      "All ECM results saved to 'ecm_all_results.csv'\n",
      "ECM predicted matches saved to 'ecm_predicted_matches.csv'\n",
      "High confidence matches (>0.8) saved to 'ecm_high_confidence_matches.csv'\n",
      "\n",
      "==================================================\n",
      "ECM CLASSIFICATION SUMMARY\n",
      "==================================================\n",
      "Total candidate pairs evaluated: 9312\n",
      "ECM predicted matches: 4\n",
      "High confidence matches (>0.8): 0\n",
      "Medium confidence matches (0.5-0.8): 4\n",
      "Low confidence matches (<0.5): 9308\n",
      "\n",
      "Match Probability Statistics:\n",
      "Mean: 0.0268\n",
      "Median: 0.0142\n",
      "Min: 0.0048\n",
      "Max: 0.7792\n",
      "\n",
      "Top 10 Most Likely Matches:\n",
      "--------------------------------------------------------------------------------\n",
      "Probability: 0.7792\n",
      "  Record 1: WB Zhang, Y Ge, Y Leung, Y Zhou - A georeferenced graph model for geospatial data matching by optimising measures of similarity across multiple scales\n",
      "  Record 2: Y Zhang, J Huang, M Deng, C Chen, F Zhou… - Automated matching of multi-scale building data based on relaxation labelling and pattern combinations\n",
      "  Similarities - Authors: 1, Title: 1, Source: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Probability: 0.7792\n",
      "  Record 1: Y Zhang, J Huang, M Deng, C Chen, F Zhou… - Automated matching of multi-scale building data based on relaxation labelling and pattern combinations\n",
      "  Record 2: WB Zhang, Y Ge, Y Leung, Y Zhou - A georeferenced graph model for geospatial data matching by optimising measures of similarity across multiple scales\n",
      "  Similarities - Authors: 1, Title: 1, Source: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Probability: 0.5441\n",
      "  Record 1: A Alali, V Kazei, B Sun, T Alkhalifah - Time-lapse data matching using a recurrent neural network approach\n",
      "  Record 2: B Sun, T Alkhalifah - The application of an optimal transport to a preconditioned data matching function for robust waveform inversion\n",
      "  Similarities - Authors: 1, Title: 0, Source: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Probability: 0.5441\n",
      "  Record 1: B Sun, T Alkhalifah - The application of an optimal transport to a preconditioned data matching function for robust waveform inversion\n",
      "  Record 2: A Alali, V Kazei, B Sun, T Alkhalifah - Time-lapse data matching using a recurrent neural network approach\n",
      "  Similarities - Authors: 1, Title: 0, Source: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Matches at different probability thresholds:\n",
      "  Threshold > 0.5: 4 matches\n",
      "  Threshold > 0.6: 2 matches\n",
      "  Threshold > 0.7: 2 matches\n",
      "  Threshold > 0.8: 0 matches\n",
      "  Threshold > 0.9: 0 matches\n",
      "\n",
      "ECM Classification completed! Check the generated CSV files for detailed results.\n"
     ]
    }
   ],
   "source": [
    "# ECM CLASSIFICATION STEP\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING ECM CLASSIFICATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare the feature matrix for ECM\n",
    "print(\"\\nPreparing feature matrix for ECM...\")\n",
    "\n",
    "# Convert comparison results to binary features (0 or 1)\n",
    "# The ECM algorithm works with binary comparison vectors\n",
    "X_data = features.astype(int)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_data.shape}\")\n",
    "print(f\"Feature columns: {list(X_data.columns)}\")\n",
    "print(f\"Sample of feature matrix:\")\n",
    "print(X_data.head())\n",
    "\n",
    "# Check for any missing values\n",
    "if X_data.isnull().sum().sum() > 0:\n",
    "    print(\"Warning: Found missing values in feature matrix. Filling with 0.\")\n",
    "    X_data = X_data.fillna(0)\n",
    "\n",
    "# Initialize the ECM Classifier\n",
    "print(\"\\nInitializing ECM Classifier...\")\n",
    "ecm_classifier = rl.ECMClassifier()\n",
    "\n",
    "# Fit the ECM model (unsupervised learning)\n",
    "print(\"Training ECM model... This may take some time.\")\n",
    "ecm_classifier.fit(X_data)\n",
    "\n",
    "print(\"\\nECM Training completed!\")\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"LEARNED ECM PARAMETERS\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Prior probability P(Match): {ecm_classifier.p:.4f}\")\n",
    "print(f\"m probabilities P(x_i=1|Match): {ecm_classifier.m_probs}\")\n",
    "print(f\"u probabilities P(x_i=1|Non-Match): {ecm_classifier.u_probs}\")\n",
    "print(f\"Feature weights: {ecm_classifier.weights}\")\n",
    "\n",
    "# Make predictions using the trained ECM model\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Predict matches\n",
    "print(\"Predicting matches...\")\n",
    "ecm_links = ecm_classifier.predict(X_data)\n",
    "print(f\"ECM predicted {len(ecm_links)} matches out of {len(X_data)} candidate pairs\")\n",
    "\n",
    "# Get match probabilities for all pairs\n",
    "print(\"Computing match probabilities...\")\n",
    "match_probabilities = ecm_classifier.prob(X_data)\n",
    "\n",
    "# Create a comprehensive results DataFrame\n",
    "print(\"\\nCreating detailed results...\")\n",
    "ecm_results = []\n",
    "\n",
    "for idx, prob in zip(X_data.index, match_probabilities):\n",
    "    idx1, idx2 = idx\n",
    "    is_predicted_match = idx in ecm_links\n",
    "    \n",
    "    ecm_results.append({\n",
    "        'Record1_Index': idx1,\n",
    "        'Record2_Index': idx2,\n",
    "        'Record1_Authors': df.loc[idx1, 'Authors'],\n",
    "        'Record1_Title': df.loc[idx1, 'Title'],\n",
    "        'Record1_Source': df.loc[idx1, 'Source'],\n",
    "        'Record2_Authors': df.loc[idx2, 'Authors'],\n",
    "        'Record2_Title': df.loc[idx2, 'Title'],\n",
    "        'Record2_Source': df.loc[idx2, 'Source'],\n",
    "        'Match_Probability': prob,\n",
    "        'ECM_Prediction': is_predicted_match,\n",
    "        'Authors_Similarity': X_data.loc[idx, 'authors'] if 'authors' in X_data.columns else 0,\n",
    "        'Title_Similarity': X_data.loc[idx, 'title'] if 'title' in X_data.columns else 0,\n",
    "        'Source_Exact_Match': X_data.loc[idx, 'source_exact'] if 'source_exact' in X_data.columns else 0\n",
    "    })\n",
    "\n",
    "ecm_results_df = pd.DataFrame(ecm_results)\n",
    "\n",
    "# Sort by match probability (highest first)\n",
    "ecm_results_df = ecm_results_df.sort_values('Match_Probability', ascending=False)\n",
    "\n",
    "# Save all results\n",
    "ecm_results_df.to_csv('ecm_all_results.csv', index=False)\n",
    "print(f\"All ECM results saved to 'ecm_all_results.csv'\")\n",
    "\n",
    "# Save only the predicted matches\n",
    "ecm_matches_df = ecm_results_df[ecm_results_df['ECM_Prediction'] == True]\n",
    "ecm_matches_df.to_csv('ecm_predicted_matches.csv', index=False)\n",
    "print(f\"ECM predicted matches saved to 'ecm_predicted_matches.csv'\")\n",
    "\n",
    "# High-confidence matches (probability > 0.8)\n",
    "high_conf_matches = ecm_results_df[ecm_results_df['Match_Probability'] > 0.8]\n",
    "high_conf_matches.to_csv('ecm_high_confidence_matches.csv', index=False)\n",
    "print(f\"High confidence matches (>0.8) saved to 'ecm_high_confidence_matches.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ECM CLASSIFICATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total candidate pairs evaluated: {len(X_data)}\")\n",
    "print(f\"ECM predicted matches: {len(ecm_matches_df)}\")\n",
    "print(f\"High confidence matches (>0.8): {len(high_conf_matches)}\")\n",
    "print(f\"Medium confidence matches (0.5-0.8): {len(ecm_results_df[(ecm_results_df['Match_Probability'] > 0.5) & (ecm_results_df['Match_Probability'] <= 0.8)])}\")\n",
    "print(f\"Low confidence matches (<0.5): {len(ecm_results_df[ecm_results_df['Match_Probability'] <= 0.5])}\")\n",
    "\n",
    "# Show some statistics about match probabilities\n",
    "print(f\"\\nMatch Probability Statistics:\")\n",
    "print(f\"Mean: {ecm_results_df['Match_Probability'].mean():.4f}\")\n",
    "print(f\"Median: {ecm_results_df['Match_Probability'].median():.4f}\")\n",
    "print(f\"Min: {ecm_results_df['Match_Probability'].min():.4f}\")\n",
    "print(f\"Max: {ecm_results_df['Match_Probability'].max():.4f}\")\n",
    "\n",
    "# Display top 10 most likely matches\n",
    "print(f\"\\nTop 10 Most Likely Matches:\")\n",
    "print(\"-\" * 80)\n",
    "for idx, row in ecm_matches_df.head(10).iterrows():\n",
    "    print(f\"Probability: {row['Match_Probability']:.4f}\")\n",
    "    print(f\"  Record 1: {row['Record1_Authors']} - {row['Record1_Title']}\")\n",
    "    print(f\"  Record 2: {row['Record2_Authors']} - {row['Record2_Title']}\")\n",
    "    print(f\"  Similarities - Authors: {row['Authors_Similarity']}, Title: {row['Title_Similarity']}, Source: {row['Source_Exact_Match']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Optional: Create different threshold-based classifications\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "print(f\"\\nMatches at different probability thresholds:\")\n",
    "for threshold in thresholds:\n",
    "    count = len(ecm_results_df[ecm_results_df['Match_Probability'] > threshold])\n",
    "    print(f\"  Threshold > {threshold}: {count} matches\")\n",
    "\n",
    "print(f\"\\nECM Classification completed! Check the generated CSV files for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
